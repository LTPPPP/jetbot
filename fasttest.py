#!/usr/bin/env python3
"""
Fast test vá»›i loading optimization vÃ  progress indicator
"""

import os
import sys
import time
import threading
import numpy as np

def show_loading_progress():
    """Hiá»ƒn thá»‹ progress loading"""
    chars = "â ‹â ™â ¹â ¸â ¼â ´â ¦â §â ‡â "
    i = 0
    while loading:
        sys.stdout.write(f"\rğŸ”„ Loading model... {chars[i % len(chars)]}")
        sys.stdout.flush()
        time.sleep(0.1)
        i += 1

def main():
    global loading
    print("ğŸš€ Fast ObjectDetector Test")
    print("=" * 30)
    
    # 1. Kiá»ƒm tra file
    model_path = "./ssd_mobilenet_v2_coco.engine"
    if not os.path.exists(model_path):
        print(f"âŒ Model khÃ´ng tá»“n táº¡i: {model_path}")
        return
    
    file_size = os.path.getsize(model_path)
    print(f"ğŸ“ Model: {model_path} ({file_size/1024/1024:.1f} MB)")
    
    # 2. Import vá»›i progress
    print("ğŸ”„ Importing libraries...")
    try:
        from jetbot.object_detection import ObjectDetector
        print("âœ… Import OK")
    except Exception as e:
        print(f"âŒ Import error: {e}")
        return
    
    # 3. Load model vá»›i progress indicator
    print("\nğŸ’¡ TensorRT engine loading (cÃ³ thá»ƒ máº¥t 30-60s trÃªn Jetson Nano)...")
    print("   - Láº§n Ä‘áº§u load sáº½ lÃ¢u nháº¥t")
    print("   - TensorRT Ä‘ang optimize engine cho GPU")
    print("   - CÃ¡c láº§n sau sáº½ nhanh hÆ¡n")
    
    loading = True
    progress_thread = threading.Thread(target=show_loading_progress)
    progress_thread.daemon = True
    progress_thread.start()
    
    try:
        start_time = time.time()
        detector = ObjectDetector(model_path)
        load_time = time.time() - start_time
        loading = False
        
        print(f"\râœ… Model loaded! ({load_time:.1f}s)                    ")
        
    except Exception as e:
        loading = False
        print(f"\râŒ Load error: {e}                    ")
        return
    
    # 4. Quick test
    print("ğŸ”„ Quick inference test...")
    dummy_image = np.random.randint(0, 255, (300, 300, 3), dtype=np.uint8)
    
    start_time = time.time()
    detections = detector(dummy_image)
    inference_time = time.time() - start_time
    
    print(f"âœ… Inference OK! ({inference_time*1000:.0f}ms)")
    print(f"ğŸ“Š Objects: {len(detections) if detections else 0}")
    
    # 5. Performance tips
    print(f"\nğŸ’¡ Performance Tips:")
    print(f"   - Load time: {load_time:.1f}s (normal cho Jetson Nano)")
    print(f"   - Inference: {inference_time*1000:.0f}ms")
    print(f"   - Expected FPS: ~{1/inference_time:.0f}")
    print(f"   - Model sáº½ load nhanh hÆ¡n láº§n sau")
    
    print(f"\nğŸ‰ Test hoÃ n thÃ nh! Model sáºµn sÃ ng sá»­ dá»¥ng.")

if __name__ == "__main__":
    loading = False
    main()