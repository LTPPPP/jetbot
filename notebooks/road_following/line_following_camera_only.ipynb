{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe1d775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import ipywidgets\n",
    "import traitlets\n",
    "from IPython.display import display\n",
    "from jetbot import Camera, Robot, bgr8_to_jpeg\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7462e4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kh·ªüi t·∫°o camera v√† robot cho computer vision line detection\n",
    "print(\"ƒêang kh·ªüi t·∫°o camera v√† robot...\")\n",
    "\n",
    "camera = Camera()\n",
    "robot = Robot()\n",
    "\n",
    "# T·∫°o widget hi·ªÉn th·ªã h√¨nh ·∫£nh g·ªëc v√† ƒë√£ x·ª≠ l√Ω\n",
    "image_widget = ipywidgets.Image(format='jpeg', width=300, height=300)\n",
    "processed_widget = ipywidgets.Image(format='jpeg', width=300, height=300)\n",
    "\n",
    "# K·∫øt n·ªëi camera v·ªõi widget g·ªëc\n",
    "traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "print(\"‚úì Camera v√† Robot ƒë√£ s·∫µn s√†ng!\")\n",
    "print(\"‚úì Widget hi·ªÉn th·ªã ƒë√£ ƒë∆∞·ª£c t·∫°o\")\n",
    "\n",
    "# Hi·ªÉn th·ªã c·∫£ hai h√¨nh ·∫£nh\n",
    "print(\"üì∑ H√¨nh ·∫£nh g·ªëc v√† ƒë√£ x·ª≠ l√Ω:\")\n",
    "display(ipywidgets.HBox([image_widget, processed_widget]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14177311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H√†m x·ª≠ l√Ω h√¨nh ·∫£nh ƒë·ªÉ detect ƒë∆∞·ªùng m√†u ƒëen\n",
    "def detect_black_line(image):\n",
    "    \"\"\"\n",
    "    Ph√°t hi·ªán ƒë∆∞·ªùng m√†u ƒëen b·∫±ng computer vision\n",
    "    Returns: (center_x, confidence) ho·∫∑c (None, 0) n·∫øu kh√¥ng t√¨m th·∫•y\n",
    "    \"\"\"\n",
    "    # Chuy·ªÉn sang grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Blur ƒë·ªÉ gi·∫£m noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Threshold ƒë·ªÉ t√¨m v√πng t·ªëi (ƒë∆∞·ªùng ƒëen)\n",
    "    # Gi√° tr·ªã th·∫•p = ƒëen, gi√° tr·ªã cao = tr·∫Øng\n",
    "    _, binary = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # Ch·ªâ quan t√¢m ƒë·∫øn n·ª≠a d∆∞·ªõi c·ªßa h√¨nh ·∫£nh\n",
    "    height, width = binary.shape\n",
    "    roi_start = int(height * 0.5)  # B·∫Øt ƒë·∫ßu t·ª´ gi·ªØa h√¨nh\n",
    "    roi = binary[roi_start:, :]\n",
    "    \n",
    "    # T√¨m contours (ƒë∆∞·ªùng vi·ªÅn)\n",
    "    contours, _ = cv2.findContours(roi, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if len(contours) == 0:\n",
    "        return None, 0, binary\n",
    "    \n",
    "    # T√¨m contour l·ªõn nh·∫•t (c√≥ th·ªÉ l√† ƒë∆∞·ªùng)\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    # Ki·ªÉm tra di·ªán t√≠ch t·ªëi thi·ªÉu\n",
    "    area = cv2.contourArea(largest_contour)\n",
    "    if area < 100:  # Qu√° nh·ªè, c√≥ th·ªÉ l√† noise\n",
    "        return None, 0, binary\n",
    "    \n",
    "    # T√≠nh to√°n center c·ªßa contour\n",
    "    M = cv2.moments(largest_contour)\n",
    "    if M[\"m00\"] != 0:\n",
    "        center_x = int(M[\"m10\"] / M[\"m00\"])\n",
    "        center_y = int(M[\"m01\"] / M[\"m00\"]) + roi_start\n",
    "        \n",
    "        # Normalize center_x v·ªÅ kho·∫£ng [-1, 1]\n",
    "        normalized_x = (center_x - width/2) / (width/2)\n",
    "        \n",
    "        # Confidence d·ª±a tr√™n di·ªán t√≠ch\n",
    "        confidence = min(area / 1000, 1.0)\n",
    "        \n",
    "        return normalized_x, confidence, binary\n",
    "    \n",
    "    return None, 0, binary\n",
    "\n",
    "def create_debug_image(original, binary, center_x=None):\n",
    "    \"\"\"T·∫°o h√¨nh ·∫£nh debug ƒë·ªÉ hi·ªÉn th·ªã\"\"\"\n",
    "    # T·∫°o h√¨nh ·∫£nh 3 channel t·ª´ binary\n",
    "    debug_img = cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # V·∫Ω ƒë∆∞·ªùng trung t√¢m\n",
    "    height, width = binary.shape\n",
    "    cv2.line(debug_img, (width//2, 0), (width//2, height), (0, 255, 0), 2)\n",
    "    \n",
    "    # V·∫Ω ƒëi·ªÉm center n·∫øu c√≥\n",
    "    if center_x is not None:\n",
    "        pixel_x = int((center_x * width/2) + width/2)\n",
    "        cv2.circle(debug_img, (pixel_x, height//2), 10, (0, 0, 255), -1)\n",
    "        \n",
    "        # V·∫Ω ƒë∆∞·ªùng t·ª´ center ƒë·∫øn ƒëi·ªÉm ph√°t hi·ªán\n",
    "        cv2.line(debug_img, (width//2, height//2), (pixel_x, height//2), (255, 0, 0), 3)\n",
    "    \n",
    "    return debug_img\n",
    "\n",
    "print(\"‚úì H√†m computer vision ƒë√£ s·∫µn s√†ng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa76ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test h√†m computer vision v·ªõi frame hi·ªán t·∫°i\n",
    "print(\"üß™ Test computer vision v·ªõi frame hi·ªán t·∫°i...\")\n",
    "\n",
    "# L·∫•y frame hi·ªán t·∫°i t·ª´ camera\n",
    "current_frame = camera.value\n",
    "\n",
    "# Test h√†m detect line\n",
    "center_x, confidence, binary = detect_black_line(current_frame)\n",
    "\n",
    "print(f\"Center X: {center_x}\")\n",
    "print(f\"Confidence: {confidence}\")\n",
    "\n",
    "# T·∫°o v√† hi·ªÉn th·ªã h√¨nh ·∫£nh debug\n",
    "debug_img = create_debug_image(current_frame, binary, center_x)\n",
    "\n",
    "# Chuy·ªÉn th√†nh JPEG ƒë·ªÉ hi·ªÉn th·ªã\n",
    "_, buffer = cv2.imencode('.jpg', debug_img)\n",
    "processed_widget.value = buffer.tobytes()\n",
    "\n",
    "print(\"‚úì Test th√†nh c√¥ng! Xem h√¨nh ·∫£nh ƒë√£ x·ª≠ l√Ω b√™n ph·∫£i.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2da27ee",
   "metadata": {},
   "source": [
    "## ƒêi·ªÅu khi·ªÉn th√¥ng s·ªë JetBot\n",
    "\n",
    "C√°c slider d∆∞·ªõi ƒë√¢y gi√∫p b·∫°n ƒëi·ªÅu ch·ªânh h√†nh vi c·ªßa robot:\n",
    "\n",
    "- **Speed Gain**: T·ªëc ƒë·ªô chung c·ªßa robot (0.0 - 1.0)\n",
    "- **Steering Gain**: ƒê·ªô m·∫°nh c·ªßa vi·ªác r·∫Ω (0.0 - 1.0) \n",
    "- **Steering Derivative**: B·ªô ƒëi·ªÅu khi·ªÉn PD cho steering (0.0 - 0.5)\n",
    "- **Steering Bias**: Hi·ªáu ch·ªânh bias tr√°i/ph·∫£i (-0.3 - 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee5adb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o c√°c slider ƒëi·ªÅu khi·ªÉn cho computer vision\n",
    "speed_gain_slider = ipywidgets.FloatSlider(\n",
    "    min=0.0, max=1.0, step=0.01, value=0.15, \n",
    "    description='Speed Gain'\n",
    ")\n",
    "\n",
    "steering_gain_slider = ipywidgets.FloatSlider(\n",
    "    min=0.0, max=2.0, step=0.01, value=0.5, \n",
    "    description='Steering Gain'\n",
    ")\n",
    "\n",
    "steering_dgain_slider = ipywidgets.FloatSlider(\n",
    "    min=0.0, max=0.5, step=0.001, value=0.05, \n",
    "    description='Steering kD'\n",
    ")\n",
    "\n",
    "steering_bias_slider = ipywidgets.FloatSlider(\n",
    "    min=-0.3, max=0.3, step=0.01, value=0.0, \n",
    "    description='Steering Bias'\n",
    ")\n",
    "\n",
    "# Threshold cho computer vision\n",
    "threshold_slider = ipywidgets.IntSlider(\n",
    "    min=30, max=120, step=5, value=60,\n",
    "    description='Black Threshold'\n",
    ")\n",
    "\n",
    "min_area_slider = ipywidgets.IntSlider(\n",
    "    min=50, max=500, step=25, value=100,\n",
    "    description='Min Area'\n",
    ")\n",
    "\n",
    "print(\"üéõÔ∏è C√°c slider ƒëi·ªÅu khi·ªÉn:\")\n",
    "display(speed_gain_slider, steering_gain_slider, steering_dgain_slider, steering_bias_slider)\n",
    "print(\"üîß Tham s·ªë computer vision:\")\n",
    "display(threshold_slider, min_area_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b800689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o slider hi·ªÉn th·ªã tr·∫°ng th√°i robot\n",
    "center_x_slider = ipywidgets.FloatSlider(\n",
    "    min=-1.0, max=1.0, description='Center X', \n",
    "    disabled=True\n",
    ")\n",
    "\n",
    "confidence_slider = ipywidgets.FloatSlider(\n",
    "    min=0, max=1.0, description='Confidence', \n",
    "    disabled=True\n",
    ")\n",
    "\n",
    "steering_slider = ipywidgets.FloatSlider(\n",
    "    min=-1.0, max=1.0, description='Steering', \n",
    "    disabled=True\n",
    ")\n",
    "\n",
    "speed_slider = ipywidgets.FloatSlider(\n",
    "    min=0, max=1.0, description='Speed', \n",
    "    disabled=True\n",
    ")\n",
    "\n",
    "print(\"üìä Hi·ªÉn th·ªã tr·∫°ng th√°i robot:\")\n",
    "display(center_x_slider, confidence_slider)\n",
    "display(steering_slider, speed_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7c6526",
   "metadata": {},
   "source": [
    "## H√†m ƒëi·ªÅu khi·ªÉn Computer Vision\n",
    "\n",
    "H√†m n√†y s·ª≠ d·ª•ng OpenCV ƒë·ªÉ:\n",
    "1. Detect ƒë∆∞·ªùng m√†u ƒëen b·∫±ng thresholding\n",
    "2. T√¨m contour l·ªõn nh·∫•t\n",
    "3. T√≠nh to√°n center c·ªßa ƒë∆∞·ªùng\n",
    "4. ƒêi·ªÅu khi·ªÉn robot theo PID controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08cfb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bi·∫øn to√†n c·ª•c cho PID controller\n",
    "steering = 0.0\n",
    "last_steering = 0.0\n",
    "\n",
    "def detect_black_line_dynamic(image):\n",
    "    \"\"\"H√†m detect line v·ªõi threshold ƒë·ªông t·ª´ slider\"\"\"\n",
    "    # Chuy·ªÉn sang grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Blur ƒë·ªÉ gi·∫£m noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Threshold v·ªõi gi√° tr·ªã t·ª´ slider\n",
    "    _, binary = cv2.threshold(blurred, threshold_slider.value, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # ROI - ch·ªâ quan t√¢m n·ª≠a d∆∞·ªõi\n",
    "    height, width = binary.shape\n",
    "    roi_start = int(height * 0.5)\n",
    "    roi = binary[roi_start:, :]\n",
    "    \n",
    "    # T√¨m contours\n",
    "    contours, _ = cv2.findContours(roi, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if len(contours) == 0:\n",
    "        return None, 0, binary\n",
    "    \n",
    "    # T√¨m contour l·ªõn nh·∫•t\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    area = cv2.contourArea(largest_contour)\n",
    "    \n",
    "    # Ki·ªÉm tra di·ªán t√≠ch t·ªëi thi·ªÉu t·ª´ slider\n",
    "    if area < min_area_slider.value:\n",
    "        return None, 0, binary\n",
    "    \n",
    "    # T√≠nh center\n",
    "    M = cv2.moments(largest_contour)\n",
    "    if M[\"m00\"] != 0:\n",
    "        center_x = int(M[\"m10\"] / M[\"m00\"])\n",
    "        normalized_x = (center_x - width/2) / (width/2)\n",
    "        confidence = min(area / 1000, 1.0)\n",
    "        return normalized_x, confidence, binary\n",
    "    \n",
    "    return None, 0, binary\n",
    "\n",
    "def execute_cv(change):\n",
    "    \"\"\"H√†m ƒëi·ªÅu khi·ªÉn ch√≠nh s·ª≠ d·ª•ng computer vision\"\"\"\n",
    "    global steering, last_steering\n",
    "    \n",
    "    try:\n",
    "        # L·∫•y h√¨nh ·∫£nh m·ªõi t·ª´ camera\n",
    "        image = change['new']\n",
    "        \n",
    "        # Ph√°t hi·ªán ƒë∆∞·ªùng b·∫±ng computer vision\n",
    "        center_x, confidence, binary = detect_black_line_dynamic(image)\n",
    "        \n",
    "        # C·∫≠p nh·∫≠t slider hi·ªÉn th·ªã\n",
    "        center_x_slider.value = center_x if center_x is not None else 0\n",
    "        confidence_slider.value = confidence\n",
    "        speed_slider.value = speed_gain_slider.value\n",
    "        \n",
    "        # T·∫°o v√† hi·ªÉn th·ªã h√¨nh ·∫£nh debug\n",
    "        debug_img = create_debug_image(image, binary, center_x)\n",
    "        _, buffer = cv2.imencode('.jpg', debug_img)\n",
    "        processed_widget.value = buffer.tobytes()\n",
    "        \n",
    "        # ƒêi·ªÅu khi·ªÉn robot n·∫øu ph√°t hi·ªán ƒë∆∞·ª£c ƒë∆∞·ªùng\n",
    "        if center_x is not None and confidence > 0.1:\n",
    "            # PID controller\n",
    "            steering = center_x * steering_gain_slider.value + (center_x - last_steering) * steering_dgain_slider.value\n",
    "            last_steering = center_x\n",
    "            \n",
    "            # √Åp d·ª•ng bias\n",
    "            steering = steering + steering_bias_slider.value\n",
    "            \n",
    "            # Gi·ªõi h·∫°n steering\n",
    "            steering = max(min(steering, 1.0), -1.0)\n",
    "            \n",
    "            # C·∫≠p nh·∫≠t slider\n",
    "            steering_slider.value = steering\n",
    "            \n",
    "            # ƒêi·ªÅu khi·ªÉn ƒë·ªông c∆°\n",
    "            left_speed = max(min(speed_slider.value + steering, 1.0), 0.0)\n",
    "            right_speed = max(min(speed_slider.value - steering, 1.0), 0.0)\n",
    "            \n",
    "            robot.left_motor.value = left_speed\n",
    "            robot.right_motor.value = right_speed\n",
    "            \n",
    "        else:\n",
    "            # Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c ƒë∆∞·ªùng - d·ª´ng robot\n",
    "            steering_slider.value = 0\n",
    "            robot.stop()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"L·ªói trong qu√° tr√¨nh ƒëi·ªÅu khi·ªÉn: {e}\")\n",
    "        robot.stop()\n",
    "\n",
    "print(\"‚úì H√†m computer vision ƒëi·ªÅu khi·ªÉn ƒë√£ s·∫µn s√†ng\")\n",
    "print(\"‚ö†Ô∏è Ch√∫ √Ω: Robot s·∫Ω di chuy·ªÉn khi ph√°t hi·ªán ƒë∆∞·ªùng m√†u ƒëen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e42e3a6",
   "metadata": {},
   "source": [
    "## üöÄ B·∫Øt ƒë·∫ßu ch·∫ø ƒë·ªô theo ƒë∆∞·ªùng\n",
    "\n",
    "**C·∫¢NH B√ÅO**: ƒê·∫£m b·∫£o robot ƒë∆∞·ª£c ƒë·∫∑t tr√™n ƒë∆∞·ªùng/track v√† c√≥ ƒë·ªß kh√¥ng gian tr∆∞·ªõc khi ch·∫°y!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d0f5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Test h√†m ƒëi·ªÅu khi·ªÉn computer vision m·ªôt l·∫ßn\n",
    "    print(\"üß™ Test h√†m ƒëi·ªÅu khi·ªÉn computer vision v·ªõi frame hi·ªán t·∫°i...\")\n",
    "    execute_cv({'new': camera.value})\n",
    "    print(\"‚úì Test th√†nh c√¥ng!\")\n",
    "\n",
    "    # B·∫Øt ƒë·∫ßu ch·∫ø ƒë·ªô theo ƒë∆∞·ªùng v·ªõi computer vision\n",
    "    print(\"üöÄ B·∫Øt ƒë·∫ßu ch·∫ø ƒë·ªô theo ƒë∆∞·ªùng v·ªõi Computer Vision...\")\n",
    "    print(\"‚ö†Ô∏è ROBOT S·∫º B·∫ÆT ƒê·∫¶U DI CHUY·ªÇN KHI PH√ÅT HI·ªÜN ƒê∆Ø·ªúNG ƒêEN!\")\n",
    "\n",
    "    camera.observe(execute_cv, names='value')\n",
    "    print(\"‚úÖ Ch·∫ø ƒë·ªô theo ƒë∆∞·ªùng Computer Vision ƒë√£ ƒë∆∞·ª£c k√≠ch ho·∫°t!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e70486",
   "metadata": {},
   "source": [
    "## üõë D·ª´ng robot\n",
    "\n",
    "Ch·∫°y cell d∆∞·ªõi ƒë√¢y ƒë·ªÉ d·ª´ng robot v√† ng·∫Øt k·∫øt n·ªëi camera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ed1b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D·ª´ng ch·∫ø ƒë·ªô theo ƒë∆∞·ªùng computer vision\n",
    "print(\"üõë ƒêang d·ª´ng robot...\")\n",
    "\n",
    "# Ng·∫Øt k·∫øt n·ªëi callback\n",
    "camera.unobserve(execute_cv, names='value')\n",
    "\n",
    "# Ch·ªù m·ªôt ch√∫t ƒë·ªÉ x·ª≠ l√Ω frame cu·ªëi c√πng\n",
    "time.sleep(0.1)\n",
    "\n",
    "# D·ª´ng robot ho√†n to√†n\n",
    "robot.stop()\n",
    "\n",
    "print(\"‚úÖ Robot ƒë√£ d·ª´ng!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62e8e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gi·∫£i ph√≥ng t√†i nguy√™n camera\n",
    "print(\"üîå ƒêang ƒë√≥ng k·∫øt n·ªëi camera...\")\n",
    "camera.stop()\n",
    "print(\"‚úÖ Camera ƒë√£ ƒë∆∞·ª£c ƒë√≥ng - c√≥ th·ªÉ s·ª≠ d·ª•ng trong notebook kh√°c!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35939c6e",
   "metadata": {},
   "source": [
    "# \udfaf Computer Vision Line Following - Detect ƒê∆∞·ªùng ƒêen\n",
    "\n",
    "## Notebook n√†y s·ª≠ d·ª•ng OpenCV ƒë·ªÉ ph√°t hi·ªán ƒë∆∞·ªùng m√†u ƒëen\n",
    "\n",
    "### \udd27 C√°ch ho·∫°t ƒë·ªông:\n",
    "1. **Chuy·ªÉn ƒë·ªïi m√†u**: BGR ‚Üí Grayscale\n",
    "2. **Blur**: Gi·∫£m noise b·∫±ng Gaussian blur  \n",
    "3. **Threshold**: T√°ch v√πng ƒëen (ƒë∆∞·ªùng) kh·ªèi n·ªÅn\n",
    "4. **Contour Detection**: T√¨m ƒë∆∞·ªùng vi·ªÅn c·ªßa v√πng ƒëen\n",
    "5. **Center Calculation**: T√≠nh to√°n t√¢m c·ªßa ƒë∆∞·ªùng\n",
    "6. **PID Control**: ƒêi·ªÅu khi·ªÉn robot theo t√¢m ƒë∆∞·ªùng\n",
    "\n",
    "### üìã C√°c b∆∞·ªõc s·ª≠ d·ª•ng:\n",
    "1. **Cell 1**: Import th∆∞ vi·ªán OpenCV\n",
    "2. **Cell 2**: Kh·ªüi t·∫°o camera, robot v√† hi·ªÉn th·ªã h√¨nh ·∫£nh\n",
    "3. **Cell 3**: ƒê·ªãnh nghƒ©a h√†m computer vision\n",
    "4. **Cell 4**: Test v·ªõi frame hi·ªán t·∫°i\n",
    "5. **Cell 5-6**: T·∫°o slider ƒëi·ªÅu khi·ªÉn\n",
    "7. **Cell 7**: H√†m ƒëi·ªÅu khi·ªÉn ch√≠nh\n",
    "8. **Cell 8**: B·∫Øt ƒë·∫ßu ch·∫ø ƒë·ªô theo ƒë∆∞·ªùng\n",
    "9. **Cell 9-10**: D·ª´ng robot v√† ƒë√≥ng camera\n",
    "\n",
    "### ‚öôÔ∏è ƒêi·ªÅu ch·ªânh th√¥ng s·ªë:\n",
    "\n",
    "**ƒêi·ªÅu khi·ªÉn Robot:**\n",
    "- **Speed Gain**: T·ªëc ƒë·ªô robot (0.1-0.3)\n",
    "- **Steering Gain**: ƒê·ªô m·∫°nh r·∫Ω (0.3-1.0) \n",
    "- **Steering kD**: Gi·∫£m dao ƒë·ªông (0.01-0.1)\n",
    "- **Steering Bias**: Hi·ªáu ch·ªânh l·ªách (-0.1 ƒë·∫øn 0.1)\n",
    "\n",
    "**Computer Vision:**\n",
    "- **Black Threshold**: Ng∆∞·ª°ng ph√°t hi·ªán m√†u ƒëen (30-120)\n",
    "- **Min Area**: Di·ªán t√≠ch t·ªëi thi·ªÉu c·ªßa ƒë∆∞·ªùng (50-500)\n",
    "\n",
    "### üéØ Tips ƒë·ªÉ c√≥ k·∫øt qu·∫£ t·ªët:\n",
    "1. **ƒê∆∞·ªùng m√†u ƒëen r√µ r√†ng**: S·ª≠ d·ª•ng bƒÉng keo ƒëen tr√™n n·ªÅn s√°ng\n",
    "2. **√Ånh s√°ng ƒë·ªÅu**: Tr√°nh b√≥ng ƒë·ªï v√† ph·∫£n quang\n",
    "3. **ƒêi·ªÅu ch·ªânh threshold**: Thay ƒë·ªïi \"Black Threshold\" ƒë·ªÉ ph√°t hi·ªán t·ªët h∆°n\n",
    "4. **B·∫Øt ƒë·∫ßu ch·∫≠m**: Speed Gain = 0.1-0.15\n",
    "5. **Quan s√°t h√¨nh debug**: Ki·ªÉm tra v√πng ƒëen ƒë∆∞·ª£c ph√°t hi·ªán\n",
    "\n",
    "### üîç Debug:\n",
    "- **H√¨nh tr√°i**: Camera g·ªëc\n",
    "- **H√¨nh ph·∫£i**: H√¨nh ƒë√£ x·ª≠ l√Ω (tr·∫Øng = ƒë∆∞·ªùng ƒëen ph√°t hi·ªán ƒë∆∞·ª£c)\n",
    "- **ƒê∆∞·ªùng xanh**: Trung t√¢m camera\n",
    "- **ƒêi·ªÉm ƒë·ªè**: T√¢m ƒë∆∞·ªùng ph√°t hi·ªán ƒë∆∞·ª£c\n",
    "- **ƒê∆∞·ªùng xanh d∆∞∆°ng**: H∆∞·ªõng steering\n",
    "\n",
    "### üö® An to√†n:\n",
    "- Robot ch·ªâ di chuy·ªÉn khi **confidence > 0.1**\n",
    "- T·ª± ƒë·ªông d·ª´ng khi kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c ƒë∆∞·ªùng\n",
    "- Lu√¥n c√≥ kh√¥ng gian an to√†n xung quanh\n",
    "\n",
    "**Ch√∫c b·∫°n th√†nh c√¥ng v·ªõi Computer Vision Line Following! ü§ñ\udcf9**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
