#!/usr/bin/env python3
"""
JetBot Camera Debug - Hi·ªÉn th·ªã ·∫£nh g·ªëc v√† ·∫£nh sau x·ª≠ l√Ω contour
S·ª≠ d·ª•ng ƒë·ªÉ debug line following
"""

import cv2
import numpy as np
from jetbot import Robot, Camera
import time
import os

# --- C·∫§U H√åNH ---

# 1. K√≠ch th∆∞·ªõc ·∫£nh t·ª´ camera
WIDTH = 640
HEIGHT = 480

# 2. V√πng quan t√¢m (Region of Interest - ROI)
ROI_Y = int(HEIGHT * 0.6)  # B·∫Øt ƒë·∫ßu t·ª´ 60% chi·ªÅu cao c·ªßa ·∫£nh
ROI_H = int(HEIGHT * 0.4)  # L·∫•y 40% chi·ªÅu cao c√≤n l·∫°i

# 3. Th√¥ng s·ªë x·ª≠ l√Ω ·∫£nh cho ƒë∆∞·ªùng ƒëen
BLACK_THRESHOLD = 20        # Ng∆∞·ª°ng ph√°t hi·ªán ƒëen (30-120)
MIN_AREA = 100             # Di·ªán t√≠ch t·ªëi thi·ªÉu c·ªßa contour

# 4. T·ªëc ƒë·ªô c·ªßa Robot
BASE_SPEED = 0.15
STEERING_GAIN = 0.5

# --- KH·ªûI T·∫†O ---
robot = Robot()
camera = Camera.instance(width=WIDTH, height=HEIGHT)

# Ki·ªÉm tra m√¥i tr∆∞·ªùng hi·ªÉn th·ªã
display_enabled = True
try:
    if not os.environ.get('DISPLAY'):
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y DISPLAY - Ch·∫°y trong ch·∫ø ƒë·ªô SSH (kh√¥ng hi·ªÉn th·ªã)")
        display_enabled = False
    else:
        # Th·ª≠ t·∫°o window test
        cv2.namedWindow('test', cv2.WINDOW_AUTOSIZE)
        cv2.destroyWindow('test')
        print("‚úÖ Display kh·∫£ d·ª•ng - S·∫Ω hi·ªÉn th·ªã c·ª≠a s·ªï debug")
except:
    print("‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫°o window - Ch·∫°y trong ch·∫ø ƒë·ªô headless")
    display_enabled = False

print("Kh·ªüi t·∫°o ho√†n t·∫•t. Robot s·∫µn s√†ng...")
if display_enabled:
    print("üì∫ S·∫Ω hi·ªÉn th·ªã 2 c·ª≠a s·ªï: 'Original' v√† 'Processed'")
    print("Nh·∫•n 'q' ƒë·ªÉ tho√°t")
else:
    print("üñ•Ô∏è Ch·∫°y trong ch·∫ø ƒë·ªô headless - ch·ªâ c√≥ log")
    print("Nh·∫•n Ctrl+C ƒë·ªÉ tho√°t")

time.sleep(2)
print("B·∫Øt ƒë·∫ßu!")

def detect_black_line(image):
    """Ph√°t hi·ªán ƒë∆∞·ªùng m√†u ƒëen v√† tr·∫£ v·ªÅ th√¥ng tin debug"""
    # L·∫•y ROI
    roi = image[ROI_Y : ROI_Y + ROI_H, :]
    
    # Chuy·ªÉn sang grayscale
    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
    
    # Blur ƒë·ªÉ gi·∫£m noise
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    
    # Threshold ƒë·ªÉ t·∫°o ·∫£nh binary (ƒëen-tr·∫Øng)
    _, binary = cv2.threshold(blurred, BLACK_THRESHOLD, 255, cv2.THRESH_BINARY_INV)
    
    # T√¨m contours
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # T·∫°o ·∫£nh debug ƒë·ªÉ hi·ªÉn th·ªã
    debug_img = cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR)
    
    # V·∫Ω ƒë∆∞·ªùng trung t√¢m (xanh l√°)
    cv2.line(debug_img, (WIDTH//2, 0), (WIDTH//2, ROI_H), (0, 255, 0), 2)
    
    center_x = None
    confidence = 0
    
    if len(contours) > 0:
        # L·ªçc contours theo di·ªán t√≠ch
        valid_contours = [c for c in contours if cv2.contourArea(c) >= MIN_AREA]
        
        if valid_contours:
            # T√¨m contour l·ªõn nh·∫•t
            largest_contour = max(valid_contours, key=cv2.contourArea)
            area = cv2.contourArea(largest_contour)
            confidence = min(area / 1000, 1.0)
            
            # V·∫Ω contour l√™n ·∫£nh debug (m√†u xanh d∆∞∆°ng)
            cv2.drawContours(debug_img, [largest_contour], -1, (255, 0, 0), 2)
            
            # T√≠nh t√¢m c·ªßa contour
            M = cv2.moments(largest_contour)
            if M["m00"] != 0:
                cx = int(M["m10"] / M["m00"])
                cy = int(M["m01"] / M["m00"])
                
                # V·∫Ω ƒëi·ªÉm t√¢m (ƒë·ªè)
                cv2.circle(debug_img, (cx, cy), 8, (0, 0, 255), -1)
                
                # V·∫Ω ƒë∆∞·ªùng t·ª´ t√¢m m√†n h√¨nh ƒë·∫øn t√¢m ƒë∆∞·ªùng (m√†u v√†ng)
                cv2.line(debug_img, (WIDTH//2, cy), (cx, cy), (0, 255, 255), 3)
                
                # Normalize center_x v·ªÅ [-1, 1]
                center_x = (cx - WIDTH/2) / (WIDTH/2)
    
    # Th√™m text th√¥ng tin
    cv2.putText(debug_img, f"Confidence: {confidence:.2f}", (10, 25), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    cv2.putText(debug_img, f"Center X: {center_x:.3f}" if center_x else "No Line", 
               (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    cv2.putText(debug_img, f"Contours: {len(contours)}", (10, 75), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    
    return center_x, confidence, debug_img

# --- V√íNG L·∫∂P CH√çNH ---
try:
    frame_count = 0
    
    while True:
        # ƒê·ªçc ·∫£nh t·ª´ camera
        image = camera.value
        
        # X·ª≠ l√Ω ph√°t hi·ªán ƒë∆∞·ªùng
        center_x, confidence, processed_img = detect_black_line(image)
        
        # T·∫°o ·∫£nh g·ªëc v·ªõi ROI ƒë∆∞·ª£c ƒë√°nh d·∫•u
        original_display = image.copy()
        
        # V·∫Ω ROI l√™n ·∫£nh g·ªëc (m√†u xanh l√°)
        cv2.rectangle(original_display, (0, ROI_Y), (WIDTH, ROI_Y + ROI_H), (0, 255, 0), 2)
        cv2.putText(original_display, "ROI", (10, ROI_Y - 10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        
        # Th√™m th√¥ng tin l√™n ·∫£nh g·ªëc
        cv2.putText(original_display, f"Frame: {frame_count}", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        cv2.putText(original_display, f"Size: {WIDTH}x{HEIGHT}", (10, 55), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # ƒêi·ªÅu khi·ªÉn robot (ƒë∆°n gi·∫£n)
        if center_x is not None and confidence > 0.1:
            # T√≠nh to√°n steering
            steering = center_x * STEERING_GAIN
            left_speed = max(0, min(1, BASE_SPEED - steering))
            right_speed = max(0, min(1, BASE_SPEED + steering))
            
            robot.left_motor.value = left_speed
            robot.right_motor.value = right_speed
            
            # Hi·ªÉn th·ªã tr·∫°ng th√°i tr√™n ·∫£nh g·ªëc
            status = f"RUNNING - L:{left_speed:.2f} R:{right_speed:.2f}"
            color = (0, 255, 0)
        else:
            robot.stop()
            status = "STOPPED - No line detected"
            color = (0, 0, 255)
            
        cv2.putText(original_display, status, (10, HEIGHT - 20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        # Hi·ªÉn th·ªã ·∫£nh n·∫øu c√≥ display
        if display_enabled:
            cv2.imshow('Original Camera', original_display)
            cv2.imshow('Processed (ROI + Contours)', processed_img)
            
            # Ki·ªÉm tra ph√≠m nh·∫•n
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q') or key == 27:  # 'q' ho·∫∑c ESC
                print("üõë Ng∆∞·ªùi d√πng y√™u c·∫ßu tho√°t...")
                break
        
        # In log m·ªói 30 frame
        if frame_count % 30 == 0:
            if center_x is not None:
                print(f"Frame {frame_count}: Center={center_x:.3f}, Confidence={confidence:.3f}")
            else:
                print(f"Frame {frame_count}: No line detected")
        
        frame_count += 1
        time.sleep(0.033)  # ~30 FPS

except KeyboardInterrupt:
    print("\nüõë Ch∆∞∆°ng tr√¨nh b·ªã gi√°n ƒëo·∫°n")
finally:
    # D·ªçn d·∫πp
    robot.stop()
    if display_enabled:
        cv2.destroyAllWindows()
    camera.stop()
    print("‚úÖ ƒê√£ d·ª´ng v√† d·ªçn d·∫πp")