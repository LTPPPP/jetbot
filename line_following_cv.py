#!/usr/bin/env python3
"""
JetBot Line Following vá»›i Computer Vision
Sá»­ dá»¥ng OpenCV Ä‘á»ƒ detect Ä‘Æ°á»ng mÃ u Ä‘en vÃ  Ä‘iá»u khiá»ƒn robot

CÃ¡ch cháº¡y:
    python3            # Normalize center_x vá» [-1, 1] vÃ  convert to float
            normalized_x = float((center_x - width/2) / (width/2))
            confidence = float(min(area / 1000, 1.0))
            
            # TÃ­nh gÃ³c cá»§a Ä‘Æ°á»ng báº±ng cÃ¡ch fit line
            angle = self._calculate_line_angle(largest_contour, roi_offset, width, height)
            
            return normalized_x, confidence, angle, binaryllowing_cv.py

Nháº¥n 'q' Ä‘á»ƒ thoÃ¡t chÆ°Æ¡ng trÃ¬nh
"""

import cv2
import numpy as np
import time
import threading
import sys
import signal
import json
import os
import select
from jetbot import Camera, Robot

# Tá»‘i Æ°u hÃ³a NumPy operations
np.seterr(invalid='ignore', over='ignore')  # Bá» qua warning khÃ´ng cáº§n thiáº¿t

# Performance monitoring (optional)
class PerformanceMonitor:
    def __init__(self):
        self.timings = {}
        self.frame_count = 0
        self.start_time = time.time()
    
    def start_timer(self, name):
        self.timings[f"{name}_start"] = time.perf_counter()
    
    def end_timer(self, name):
        if f"{name}_start" in self.timings:
            duration = time.perf_counter() - self.timings[f"{name}_start"]
            if name not in self.timings:
                self.timings[name] = []
            self.timings[name].append(duration)
            if len(self.timings[name]) > 30:  # Chá»‰ giá»¯ 30 samples gáº§n nháº¥t
                self.timings[name].pop(0)
    
    def get_average(self, name):
        if name in self.timings and self.timings[name]:
            return sum(self.timings[name]) / len(self.timings[name])
        return 0
    
    def get_fps(self):
        self.frame_count += 1
        elapsed = time.time() - self.start_time
        return self.frame_count / elapsed if elapsed > 0 else 0

class LineFollower:
    def draw_birdview_polygon(self, image):
        """Váº½ cÃ¡c Ä‘iá»ƒm birdview (src points) lÃªn áº£nh gá»‘c Ä‘á»ƒ debug"""
        img = image.copy()
        h, w = img.shape[:2]
        # Láº¥y cÃ¡c Ä‘iá»ƒm tá»« config
        pts = [
            (int(self.src_bottom_left[0] * w), int(self.src_bottom_left[1] * h)),
            (int(self.src_bottom_right[0] * w), int(self.src_bottom_right[1] * h)),
            (int(self.src_top_right[0] * w), int(self.src_top_right[1] * h)),
            (int(self.src_top_left[0] * w), int(self.src_top_left[1] * h)),
        ]
        # Váº½ polygon
        cv2.polylines(img, [np.array(pts, np.int32).reshape((-1,1,2))], isClosed=True, color=(0,255,255), thickness=2)
        # Váº½ cÃ¡c Ä‘iá»ƒm
        for i, p in enumerate(pts):
            cv2.circle(img, p, 6, (0,0,255), -1)
            cv2.putText(img, f"P{i+1}", (p[0]+5, p[1]-5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)
        return img
    def __init__(self, config_file="config.txt"):
        print("ğŸ¤– Khá»Ÿi táº¡o JetBot Line Follower...")
        
        # Khá»Ÿi táº¡o camera vÃ  robot
        self.camera = Camera()
        self.robot = Robot()
        
        self.config_file = config_file
        
        # ThÃ´ng sá»‘ máº·c Ä‘á»‹nh (sáº½ Ä‘Æ°á»£c ghi Ä‘Ã¨ bá»Ÿi config file náº¿u cÃ³)
        self.default_config = {
            # ThÃ´ng sá»‘ Ä‘iá»u khiá»ƒn
            "speed_gain": 0.15,             # Tá»‘c Ä‘á»™ cÆ¡ báº£n (0.0-1.0)
            "steering_gain": 0.5,           # Äá»™ máº¡nh steering (0.0-2.0)
            "steering_kd": 0.05,            # Derivative gain (0.0-0.5)
            "steering_bias": 0.0,           # Bias trÃ¡i/pháº£i (-0.3-0.3)
            "angle_factor": 0.3,            # Factor cho angle steering (0.0-1.0)
            
            # ThÃ´ng sá»‘ computer vision
            "black_threshold": 60,          # NgÆ°á»¡ng phÃ¡t hiá»‡n Ä‘en (30-120)
            "min_area": 100,                # Diá»‡n tÃ­ch tá»‘i thiá»ƒu (50-500)
            "confidence_threshold": 0.1,    # NgÆ°á»¡ng tin cáº­y tá»‘i thiá»ƒu (0.0-1.0)
            
            # ThÃ´ng sá»‘ cháº¿ Ä‘á»™ cháº¡y
            "run": True,                     # True: cháº¡y theo Ä‘Æ°á»ng, False: chá»‰ align vÃ o giá»¯a
            "alignment_threshold": 0.1,      # NgÆ°á»¡ng Ä‘á»ƒ coi lÃ  Ä‘Ã£ align (0.0-0.5)
            
            # ThÃ´ng sá»‘ Bird's Eye View
            "birdview_enabled": True,       # Báº­t/táº¯t cháº¿ Ä‘á»™ bird's eye view
            "birdview_width": 160,          # Chiá»u rá»™ng bird's eye view (tá»‘i Æ°u cho JetBot)
            "birdview_height": 240,         # Chiá»u cao bird's eye view (tá»‘i Æ°u cho JetBot)
            "birdview_interpolation": "linear",  # linear, nearest, cubic
            "src_image_scale": 0.75,        # Scale down input image Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™
            
            # ThÃ´ng sá»‘ perspective transform (tá»· lá»‡ tá»« 0.0-1.0) - Má»Ÿ rá»™ng gÃ³c nhÃ¬n
            "src_bottom_left": [0.05, 0.95],   # Má»Ÿ rá»™ng tá»« 0.15 -> 0.05 (rá»™ng hÆ¡n)
            "src_bottom_right": [0.95, 0.95],  # Má»Ÿ rá»™ng tá»« 0.85 -> 0.95 (rá»™ng hÆ¡n)
            "src_top_right": [0.65, 0.45],     # Äáº©y gÃ³c trÃªn lÃªn cao hÆ¡n
            "src_top_left": [0.35, 0.45],      # Äáº©y gÃ³c trÃªn lÃªn cao hÆ¡n
            "dst_margin": 0.1,                 # Giáº£m margin tá»« 0.15 -> 0.1 Ä‘á»ƒ táº­n dá»¥ng space
            "enable_roi_optimization": True,  # Chá»‰ xá»­ lÃ½ ROI quan trá»ng
        }
        
        # Load config tá»« file
        self.load_config()
        
        # ThÃ´ng sá»‘ Bird's Eye View - Tá»‘i Æ°u hÃ³a
        self.perspective_matrix = None  # Ma tráº­n perspective transform
        self.inverse_matrix = None      # Ma tráº­n inverse transform
        self.interpolation_flag = cv2.INTER_LINEAR  # Interpolation method
        self.scaled_width = 640         # KÃ­ch thÆ°á»›c áº£nh sau scale
        self.scaled_height = 480        # KÃ­ch thÆ°á»›c áº£nh sau scale
        self._transform_cache = {}       # Cache cho cÃ¡c ma tráº­n transform
        
        # Biáº¿n tráº¡ng thÃ¡i
        self.running = False
        self.last_steering = 0.0
        self.current_frame = None
        self.debug_frame = None
        self.birdview_frame = None
        self.is_aligned = False             # Tráº¡ng thÃ¡i Ä‘Ã£ align chÆ°a

        # Ghi video
        self.recording_enabled = True  # Báº­t/táº¯t chá»©c nÄƒng quay video
        self.video_writer = None
        self.video_filename = None
        self.video_fps = 20
        self.video_size = (640, 480)  # Sá»­a náº¿u cáº§n
        
        # Performance monitoring
        self.perf_monitor = PerformanceMonitor() if hasattr(self, 'enable_performance_monitoring') else None
        
        # PhÃ¡t hiá»‡n mÃ´i trÆ°á»ng cháº¡y
        self.display_enabled = self._check_display_available()
        
        # Khá»Ÿi táº¡o perspective transform
        self._setup_perspective_transform()
        
        # LÆ°u áº£nh debug má»—i 1s
        self.last_debug_save_time = 0
        self.debug_save_dir = "debug_images"
        if not os.path.exists(self.debug_save_dir):
            os.makedirs(self.debug_save_dir)
        print("âœ… Khá»Ÿi táº¡o thÃ nh cÃ´ng!")
        self.print_config()

    def _check_display_available(self):
        """Kiá»ƒm tra xem cÃ³ thá»ƒ hiá»ƒn thá»‹ GUI khÃ´ng (phÃ¡t hiá»‡n SSH session)"""
        try:
            # Kiá»ƒm tra biáº¿n mÃ´i trÆ°á»ng DISPLAY
            if not os.environ.get('DISPLAY'):
                print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y DISPLAY - Cháº¡y trong cháº¿ Ä‘á»™ SSH (khÃ´ng hiá»ƒn thá»‹)")
                return False
            
            # Kiá»ƒm tra SSH session
            if os.environ.get('SSH_CLIENT') or os.environ.get('SSH_TTY'):
                print("âš ï¸ PhÃ¡t hiá»‡n SSH session - Táº¯t hiá»ƒn thá»‹ GUI")
                return False
            
            # Thá»­ táº¡o window test
            try:
                cv2.namedWindow('test', cv2.WINDOW_AUTOSIZE)
                cv2.destroyWindow('test')
                print("âœ… Display kháº£ dá»¥ng - Sáº½ hiá»ƒn thá»‹ cá»­a sá»• debug")
                return True
            except:
                print("âš ï¸ KhÃ´ng thá»ƒ táº¡o window - Cháº¡y trong cháº¿ Ä‘á»™ headless")
                return False
                
        except Exception as e:
            print(f"âš ï¸ Lá»—i khi kiá»ƒm tra display: {e} - Táº¯t hiá»ƒn thá»‹")
            return False

    def load_config(self):
        """Load thÃ´ng sá»‘ tá»« config file"""
        try:
            if os.path.exists(self.config_file):
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    
                # Merge vá»›i default config
                for key, value in self.default_config.items():
                    setattr(self, key, config.get(key, value))
                    
                print(f"âœ… ÄÃ£ load config tá»« {self.config_file}")
            else:
                # Sá»­ dá»¥ng default config vÃ  táº¡o file má»›i
                for key, value in self.default_config.items():
                    setattr(self, key, value)
                    
                self.save_config()
                print(f"ğŸ“ ÄÃ£ táº¡o config máº·c Ä‘á»‹nh: {self.config_file}")
                
        except Exception as e:
            print(f"âš ï¸ Lá»—i khi load config: {e}")
            print("ğŸ”„ Sá»­ dá»¥ng thÃ´ng sá»‘ máº·c Ä‘á»‹nh")
            
            # Fallback to default
            for key, value in self.default_config.items():
                setattr(self, key, value)

    def save_config(self):
        """LÆ°u thÃ´ng sá»‘ hiá»‡n táº¡i vÃ o config file"""
        try:
            config = {}
            for key in self.default_config.keys():
                config[key] = getattr(self, key)
                
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=4, ensure_ascii=False)
                
            print(f"ğŸ’¾ ÄÃ£ lÆ°u config vÃ o {self.config_file}")
            
        except Exception as e:
            print(f"âŒ Lá»—i khi lÆ°u config: {e}")
    
    def toggle_run_mode(self):
        """Toggle cháº¿ Ä‘á»™ run vÃ  lÆ°u vÃ o config"""
        self.run = not self.run
        self.save_config()
        mode = "Follow Line" if self.run else "Alignment Only"
        print(f"ğŸ”„ Chuyá»ƒn Ä‘á»•i cháº¿ Ä‘á»™: {mode}")
        print(f"   Run mode: {self.run}")
        
    def console_input_loop(self):
        """Xá»­ lÃ½ input tá»« console trong cháº¿ Ä‘á»™ headless"""
        while self.running:
            try:
                # Kiá»ƒm tra cÃ³ input trong 1 giÃ¢y
                if select.select([sys.stdin], [], [], 1.0)[0]:
                    line = sys.stdin.readline().strip()
                    if line.lower() == 'r':
                        self.toggle_run_mode()
                    elif line.lower() == 'q':
                        print("ğŸ›‘ NgÆ°á»i dÃ¹ng yÃªu cáº§u thoÃ¡t...")
                        self.stop()
                        break
            except:
                # Ignore input errors trong headless mode
                continue

    def print_config(self):
        """In ra thÃ´ng sá»‘ hiá»‡n táº¡i"""
        print(f"ğŸ“Š ThÃ´ng sá»‘ hiá»‡n táº¡i (tá»« {self.config_file}):")
        print(f"   ğŸ® Äiá»u khiá»ƒn:")
        print(f"      Speed Gain: {self.speed_gain}")
        print(f"      Steering Gain: {self.steering_gain}")
        print(f"      Steering kD: {self.steering_kd}")
        print(f"      Steering Bias: {self.steering_bias}")
        print(f"      Angle Factor: {self.angle_factor}")
        print(f"   ğŸ“· Computer Vision:")
        print(f"      Black Threshold: {self.black_threshold}")
        print(f"      Min Area: {self.min_area}")
        print(f"      Confidence Threshold: {self.confidence_threshold}")
        print(f"   ğŸ¯ Cháº¿ Ä‘á»™ cháº¡y:")
        print(f"      Run Mode: {'Follow Line' if self.run else 'Alignment Only'}")
        print(f"      Alignment Threshold: {self.alignment_threshold}")
        print(f"   ğŸ¦… Bird's Eye View:")
        print(f"      Enabled: {'Yes' if self.birdview_enabled else 'No'}")
        print(f"      Size: {self.birdview_width}x{self.birdview_height}")
        print(f"   ğŸ“º Display:")
        print(f"      GUI Display: {'Enabled' if self.display_enabled else 'Disabled (SSH/Headless)'}")

    def _setup_perspective_transform(self):
        """Thiáº¿t láº­p ma tráº­n perspective transform tá»‘i Æ°u cho bird's eye view"""
        # KÃ­ch thÆ°á»›c camera JetBot vá»›i tá»‘i Æ°u scale
        base_width, base_height = 640, 480
        self.scaled_width = int(base_width * getattr(self, 'src_image_scale', 0.75))
        self.scaled_height = int(base_height * getattr(self, 'src_image_scale', 0.75))
        
        # Thiáº¿t láº­p interpolation method
        interp_method = getattr(self, 'birdview_interpolation', 'linear')
        interpolation_map = {
            'nearest': cv2.INTER_NEAREST,    # Nhanh nháº¥t, cháº¥t lÆ°á»£ng tháº¥p
            'linear': cv2.INTER_LINEAR,      # CÃ¢n báº±ng tá»‘c Ä‘á»™/cháº¥t lÆ°á»£ng
            'cubic': cv2.INTER_CUBIC,        # Cháº­m hÆ¡n, cháº¥t lÆ°á»£ng cao
            'area': cv2.INTER_AREA           # Tá»‘t cho downsampling
        }
        self.interpolation_flag = interpolation_map.get(interp_method, cv2.INTER_LINEAR)
        
        # Äá»‹nh nghÄ©a 4 Ä‘iá»ƒm trong hÃ¬nh áº£nh gá»‘c (scaled) tá»« config
        src_points = np.float32([
            [self.scaled_width * self.src_bottom_left[0], self.scaled_height * self.src_bottom_left[1]],    
            [self.scaled_width * self.src_bottom_right[0], self.scaled_height * self.src_bottom_right[1]],  
            [self.scaled_width * self.src_top_right[0], self.scaled_height * self.src_top_right[1]],        
            [self.scaled_width * self.src_top_left[0], self.scaled_height * self.src_top_left[1]]           
        ], dtype=np.float32)  # Explicit dtype for optimization
        
        # Äá»‹nh nghÄ©a 4 Ä‘iá»ƒm trong bird's eye view tá»« config
        margin = self.dst_margin
        dst_points = np.float32([
            [self.birdview_width * margin, self.birdview_height],                    
            [self.birdview_width * (1-margin), self.birdview_height],               
            [self.birdview_width * (1-margin), 0],                                  
            [self.birdview_width * margin, 0]                                       
        ], dtype=np.float32)  # Explicit dtype for optimization
        
        # TÃ­nh ma tráº­n perspective transform
        self.perspective_matrix = cv2.getPerspectiveTransform(src_points, dst_points)
        self.inverse_matrix = cv2.getPerspectiveTransform(dst_points, src_points)
        
        # Cache key cho optimization
        cache_key = f"{self.scaled_width}x{self.scaled_height}_{self.birdview_width}x{self.birdview_height}"
        self._transform_cache[cache_key] = {
            'perspective': self.perspective_matrix.copy(),
            'inverse': self.inverse_matrix.copy()
        }
        
        print(f"ğŸ“ Perspective transform Ä‘Ã£ Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a:")
        print(f"   Input size: {base_width}x{base_height} -> {self.scaled_width}x{self.scaled_height} (scale: {getattr(self, 'src_image_scale', 0.75)})")
        print(f"   Interpolation: {interp_method} ({self.interpolation_flag})")
        print(f"   Source points: {src_points.astype(int).tolist()}")
        print(f"   Bird's eye size: {self.birdview_width}x{self.birdview_height}")
        print(f"   ROI optimization: {'Enabled' if getattr(self, 'enable_roi_optimization', True) else 'Disabled'}")

    def get_birdview(self, image):
        """Chuyá»ƒn Ä‘á»•i hÃ¬nh áº£nh sang bird's eye view vá»›i tá»‘i Æ°u hÃ³a"""
        if not self.birdview_enabled or self.perspective_matrix is None:
            return image
        
        # Tá»‘i Æ°u: Scale down input image náº¿u cáº§n
        if hasattr(self, 'src_image_scale') and self.src_image_scale != 1.0:
            scaled_image = cv2.resize(
                image, 
                (self.scaled_width, self.scaled_height),
                interpolation=self.interpolation_flag
            )
        else:
            scaled_image = image
            
        # Ãp dá»¥ng perspective transform vá»›i interpolation tá»‘i Æ°u
        birdview = cv2.warpPerspective(
            scaled_image, 
            self.perspective_matrix, 
            (self.birdview_width, self.birdview_height),
            flags=self.interpolation_flag,
            borderMode=cv2.BORDER_CONSTANT,
            borderValue=(255, 255, 255)  # White borders
        )
        return birdview

    def detect_black_line(self, image):
        """
        PhÃ¡t hiá»‡n Ä‘Æ°á»ng mÃ u Ä‘en báº±ng computer vision vá»›i tá»‘i Æ°u hÃ³a
        Returns: (center_x, confidence, angle, binary) hoáº·c (None, 0, 0, binary)
        """
        # Chuyá»ƒn sang bird's eye view náº¿u Ä‘Æ°á»£c báº­t vá»›i tá»‘i Æ°u hÃ³a
        if self.birdview_enabled:
            processed_image = self.get_birdview(image)
            self.birdview_frame = processed_image.copy()
        else:
            # Tá»‘i Æ°u: Scale down input image ngay cáº£ khi khÃ´ng dÃ¹ng birdview
            if hasattr(self, 'src_image_scale') and self.src_image_scale != 1.0:
                processed_image = cv2.resize(
                    image, 
                    (self.scaled_width, self.scaled_height),
                    interpolation=self.interpolation_flag
                )
            else:
                processed_image = image
            
        # Tá»‘i Æ°u: ROI-first processing Ä‘á»ƒ giáº£m tÃ­nh toÃ¡n
        height, width = processed_image.shape[:2]
        roi_enabled = getattr(self, 'enable_roi_optimization', True)
        
        if roi_enabled:
            # Chá»‰ xá»­ lÃ½ ROI quan trá»ng (ná»­a dÆ°á»›i)
            roi_start = int(height * 0.6)  # Tá»‘i Æ°u hÃ³a: 60% thay vÃ¬ 50%
            roi_image = processed_image[roi_start:, :].copy()  # Copy Ä‘á»ƒ trÃ¡nh memory issues
        else:
            roi_image = processed_image
            roi_start = 0
            
        # Chuyá»ƒn sang grayscale vá»›i memory-efficient operation
        if len(roi_image.shape) == 3:
            # Tá»‘i Æ°u: sá»­ dá»¥ng weighted grayscale cho accuracy cao hÆ¡n
            gray = cv2.cvtColor(roi_image, cv2.COLOR_BGR2GRAY)
        else:
            gray = roi_image
        
        # Blur vá»›i kernel size tá»‘i Æ°u cho JetBot
        kernel_size = 3 if min(gray.shape) < 200 else 5  # Adaptive kernel size
        blurred = cv2.GaussianBlur(gray, (kernel_size, kernel_size), 0)
        
        # Threshold vá»›i adaptive method cho lighting conditions khÃ¡c nhau
        if hasattr(self, 'adaptive_threshold') and getattr(self, 'adaptive_threshold', False):
            binary = cv2.adaptiveThreshold(
                blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                cv2.THRESH_BINARY_INV, 11, 2
            )
        else:
            _, binary = cv2.threshold(blurred, self.black_threshold, 255, cv2.THRESH_BINARY_INV)
        
        # TÃ¬m contours vá»›i tá»‘i Æ°u hÃ³a
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if len(contours) == 0:
            return None, 0, 0, binary
        
        # Tá»‘i Æ°u: Lá»c contours theo diá»‡n tÃ­ch trÆ°á»›c khi xá»­ lÃ½
        valid_contours = [c for c in contours if cv2.contourArea(c) >= self.min_area]
        
        if not valid_contours:
            return None, 0, 0, binary
        
        # TÃ¬m contour lá»›n nháº¥t trong cÃ¡c contour há»£p lá»‡
        largest_contour = max(valid_contours, key=cv2.contourArea)
        area = cv2.contourArea(largest_contour)
        
        # TÃ­nh center vÃ  angle vá»›i vectorized operations
        M = cv2.moments(largest_contour)
        if M["m00"] != 0:
            center_x = int(M["m10"] / M["m00"])
            center_y = int(M["m01"] / M["m00"]) + roi_start
            
            # Normalize center_x vá» [-1, 1] vá»›i float conversion tá»‘i Æ°u
            # Äáº£o ngÆ°á»£c dáº¥u Ä‘á»ƒ sá»­a váº¥n Ä‘á» steering ngÆ°á»£c
            current_width = binary.shape[1]
            normalized_x = float(-(center_x - current_width/2) / (current_width/2))
            
            # Confidence calculation tá»‘i Æ°u hÃ³a
            confidence = float(min(area / 1000, 1.0))
            
            # TÃ­nh gÃ³c cá»§a Ä‘Æ°á»ng báº±ng cÃ¡ch fit line
            angle = self._calculate_line_angle(largest_contour, roi_start, current_width, height)
            
            return normalized_x, confidence, angle, binary
        
        return None, 0, 0, binary

    def _calculate_line_angle(self, contour, roi_offset, width, height):
        """TÃ­nh gÃ³c cá»§a Ä‘Æ°á»ng tá»« contour vá»›i tá»‘i Æ°u hÃ³a"""
        try:
            # Tá»‘i Æ°u: Kiá»ƒm tra kÃ­ch thÆ°á»›c contour trÆ°á»›c khi xá»­ lÃ½
            if len(contour) < 5:  # Cáº§n Ã­t nháº¥t 5 Ä‘iá»ƒm cho fitLine
                return 0.0
            
            # Fit má»™t Ä‘Æ°á»ng tháº³ng qua contour vá»›i optimization
            [vx, vy, x, y] = cv2.fitLine(
                contour, 
                cv2.DIST_L2,    # Distance type - L2 is good balance
                0,              # Parameter (not used for L2)
                0.01,           # Radius accuracy
                0.01            # Angle accuracy
            )
            
            # TÃ­nh gÃ³c tá»« vector direction (vx, vy) - sá»­a lá»—i steering ngÆ°á»£c
            # Äáº£o ngÆ°á»£c vx Ä‘á»ƒ sá»­a váº¥n Ä‘á» quáº¹o ngÆ°á»£c chiá»u
            angle_rad = np.arctan2(float(-vx), float(vy))  # GÃ³c theo radian (Ä‘áº£o dáº¥u vx)
            angle_deg = np.degrees(angle_rad)  # Chuyá»ƒn sang Ä‘á»™
            
            # Normalize gÃ³c vá» [-90, 90] Ä‘á»™ - optimized  
            # FIXED: Sau khi Ä‘áº£o ngÆ°á»£c vx, giá» Ã¢m = ráº½ trÃ¡i, dÆ°Æ¡ng = ráº½ pháº£i (Ä‘Ãºng)
            angle_deg = angle_deg % 360
            if angle_deg > 180:
                angle_deg -= 360
            angle_deg = np.clip(angle_deg, -90, 90)
                
            return float(angle_deg)
            
        except Exception as e:
            # Fallback gracefully
            return 0.0

    def create_debug_image(self, original, binary, center_x=None, confidence=0, steering=0, angle=0):
        """Táº¡o hÃ¬nh áº£nh debug Ä‘á»ƒ hiá»ƒn thá»‹"""
        height, width = binary.shape
        
        # Táº¡o hÃ¬nh áº£nh 3 channel
        debug_img = cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR)
        
        # Váº½ Ä‘Æ°á»ng trung tÃ¢m (xanh lÃ¡)
        cv2.line(debug_img, (width//2, 0), (width//2, height), (0, 255, 0), 2)
        
        # Váº½ Ä‘iá»ƒm center náº¿u cÃ³ (Ä‘á»)
        if center_x is not None:
            pixel_x = int((center_x * width/2) + width/2)
            cv2.circle(debug_img, (pixel_x, height//2), 8, (0, 0, 255), -1)
            
            # Váº½ Ä‘Æ°á»ng steering (xanh dÆ°Æ¡ng)
            cv2.line(debug_img, (width//2, height//2), (pixel_x, height//2), (255, 0, 0), 3)
            
            # Váº½ vector hÆ°á»›ng cá»§a Ä‘Æ°á»ng dá»±a trÃªn angle (mÃ u tÃ­m)
            angle_rad = np.radians(angle)
            end_x = int(pixel_x + 30 * np.sin(angle_rad))
            end_y = int(height//2 - 30 * np.cos(angle_rad))
            cv2.arrowedLine(debug_img, (pixel_x, height//2), (end_x, end_y), (255, 0, 255), 2)
        
        # ThÃªm text thÃ´ng tin
        cv2.putText(debug_img, f"Confidence: {confidence:.2f}", (10, 25), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        cv2.putText(debug_img, f"Center X: {center_x:.3f}" if center_x else "No Line", 
                   (10, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        cv2.putText(debug_img, f"Angle: {angle:.1f}Â°", (10, 65), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        cv2.putText(debug_img, f"Steering: {steering:.3f}", (10, 85), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # ThÃªm thÃ´ng tin vá» cháº¿ Ä‘á»™ cháº¡y
        mode_text = "RUN" if hasattr(self, 'run') and self.run else "ALIGN"
        mode_color = (0, 255, 0) if hasattr(self, 'run') and self.run else (255, 255, 0)
        cv2.putText(debug_img, f"Mode: {mode_text}", (10, 105), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, mode_color, 1)
        
        cv2.putText(debug_img, "Press 'q' to quit", (10, height-10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 1)
        
        return debug_img

    def create_combined_debug_image(self, original, debug_processed, birdview=None):
        """Táº¡o hÃ¬nh áº£nh káº¿t há»£p giá»¯a original, processed vÃ  bird's eye view, cÃ³ váº½ polygon birdview lÃªn áº£nh gá»‘c"""
        # Váº½ polygon lÃªn áº£nh gá»‘c
        original_with_poly = self.draw_birdview_polygon(original)
        if birdview is None or not self.birdview_enabled:
            # Chá»‰ hiá»ƒn thá»‹ original vÃ  processed
            combined = np.hstack([
                cv2.resize(original_with_poly, (300, 300)),
                cv2.resize(debug_processed, (300, 300))
            ])
        else:
            # Hiá»ƒn thá»‹ cáº£ 3: original+poly, bird's eye view, processed
            original_resized = cv2.resize(original_with_poly, (200, 200))
            birdview_resized = cv2.resize(birdview, (200, 200))
            processed_resized = cv2.resize(debug_processed, (200, 200))
            # Táº¡o layout 2x2 (chá»‰ dÃ¹ng 3 Ã´)
            top_row = np.hstack([original_resized, birdview_resized])
            bottom_row = np.hstack([processed_resized, np.zeros((200, 200, 3), dtype=np.uint8)])
            combined = np.vstack([top_row, bottom_row])
            # ThÃªm label cho má»—i view
            cv2.putText(combined, "Original+Poly", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            cv2.putText(combined, "Bird's Eye", (210, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            cv2.putText(combined, "Processed", (10, 220), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        return combined

    def camera_callback(self, change):
        """Callback Ä‘Æ°á»£c gá»i khi cÃ³ frame má»›i tá»« camera"""
        self.current_frame = change['new'].copy()

    def control_loop(self):
        """VÃ²ng láº·p Ä‘iá»u khiá»ƒn chÃ­nh vá»›i performance monitoring"""
        print("ğŸš€ Báº¯t Ä‘áº§u Ä‘iá»u khiá»ƒn robot...")
        if self.display_enabled:
            print("ğŸ“¹ Hiá»ƒn thá»‹ cá»­a sá»• camera - nháº¥n 'q' Ä‘á»ƒ thoÃ¡t, 'r' Ä‘á»ƒ chuyá»ƒn cháº¿ Ä‘á»™")
        else:
            print("ğŸ–¥ï¸ Cháº¡y trong cháº¿ Ä‘á»™ headless - chá»‰ cÃ³ log trong terminal")
        
        frame_count = 0
        last_perf_report = time.time()
        
        # Khá»Ÿi Ä‘á»™ng ghi video náº¿u báº­t
        if self.recording_enabled and self.video_writer is None:
            timestr = time.strftime("%Y%m%d-%H%M%S")
            self.video_filename = f"jetbot_run_{timestr}.avi"
            fourcc = cv2.VideoWriter_fourcc(*'XVID')
            self.video_writer = cv2.VideoWriter(self.video_filename, fourcc, self.video_fps, self.video_size)
            print(f"ğŸ¥ Äang ghi video vÃ o {self.video_filename}")
        
        while self.running:
            if self.current_frame is None:
                time.sleep(0.01)
                continue
                
            try:
                # Performance monitoring start
                if self.perf_monitor:
                    self.perf_monitor.start_timer('total_frame')
                    self.perf_monitor.start_timer('detect_line')
                
                # PhÃ¡t hiá»‡n Ä‘Æ°á»ng vá»›i bird's eye view tá»‘i Æ°u hÃ³a
                center_x, confidence, angle, binary = self.detect_black_line(self.current_frame)
                
                if self.perf_monitor:
                    self.perf_monitor.end_timer('detect_line')
                    self.perf_monitor.start_timer('control_logic')
                
                # Äiá»u khiá»ƒn robot
                steering = 0.0
                if center_x is not None and confidence > self.confidence_threshold:
                    # Kiá»ƒm tra tráº¡ng thÃ¡i alignment
                    is_well_aligned = abs(center_x) < self.alignment_threshold
                    
                    if self.run or not is_well_aligned:
                        # Cháº¿ Ä‘á»™ run=True HOáº¶C chÆ°a align Ä‘Ãºng thÃ¬ tiáº¿p tá»¥c Ä‘iá»u khiá»ƒn
                        
                        # Enhanced PID controller sá»­ dá»¥ng cáº£ center_x vÃ  angle
                        # Steering dá»±a trÃªn center position
                        position_steering = center_x * self.steering_gain
                        
                        # Steering dá»±a trÃªn angle cá»§a Ä‘Æ°á»ng (preview steering)
                        # Chá»‰ sá»­ dá»¥ng angle steering khi á»Ÿ cháº¿ Ä‘á»™ run
                        angle_steering = 0.0
                        if self.run:
                            angle_steering = np.sin(np.radians(angle)) * self.angle_factor
                        
                        # Káº¿t há»£p cáº£ hai
                        steering = (position_steering + angle_steering + 
                                   (center_x - self.last_steering) * self.steering_kd + 
                                   self.steering_bias)
                        
                        # Convert to float and limit steering
                        steering = float(max(min(steering, 1.0), -1.0))
                        self.last_steering = center_x
                        
                        # Äiá»u khiá»ƒn Ä‘á»™ng cÆ¡
                        left_speed = max(min(self.speed_gain - steering, 1.0), 0.0)
                        right_speed = max(min(self.speed_gain + steering, 1.0), 0.0)

                        print(f"Debug: steering={steering}, left_speed={left_speed}, right_speed={right_speed}")
                        
                        # Convert to float to avoid numpy array error
                        self.robot.left_motor.value = float(left_speed)
                        self.robot.right_motor.value = float(right_speed)
                        
                        # Cáº­p nháº­t tráº¡ng thÃ¡i alignment
                        if not self.is_aligned and is_well_aligned and not self.run:
                            self.is_aligned = True
                            print("âœ… Robot Ä‘Ã£ align vÃ o giá»¯a Ä‘Æ°á»ng - dá»«ng láº¡i")
                        
                        # In thÃ´ng tin (má»—i 30 frame)
                        if int(time.time() * 30) % 30 == 0:
                            mode_str = "RUN" if self.run else "ALIGN"
                            align_str = "âœ…" if is_well_aligned else "âŒ"
                            print(f"ğŸ¯ [{mode_str}] Center: {center_x:.3f} {align_str}, Angle: {angle:.1f}Â°, "
                                  f"Confidence: {confidence:.3f}, Steering: {steering:.3f}, "
                                  f"Speed: L={left_speed:.3f} R={right_speed:.3f}")
                    else:
                        # Cháº¿ Ä‘á»™ alignment vÃ  Ä‘Ã£ align xong - dá»«ng robot
                        self.robot.stop()
                        if not self.is_aligned:
                            self.is_aligned = True
                            print("âœ… Robot Ä‘Ã£ align vÃ o giá»¯a Ä‘Æ°á»ng - dá»«ng láº¡i")
                        
                        # In thÃ´ng bÃ¡o alignment (Ã­t hÆ¡n)
                        if int(time.time() * 5) % 30 == 0:
                            print(f"â¸ï¸ [ALIGNED] Center: {center_x:.3f} âœ… - Robot Ä‘ang dá»«ng")
                else:
                    # KhÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c Ä‘Æ°á»ng - dá»«ng
                    self.robot.stop()
                    self.is_aligned = False  # Reset tráº¡ng thÃ¡i alignment
                    if int(time.time() * 10) % 30 == 0:  # In Ã­t hÆ¡n khi khÃ´ng tháº¥y Ä‘Æ°á»ng
                        print("âš ï¸ KhÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c Ä‘Æ°á»ng - Robot dá»«ng")
                
                # Táº¡o debug image chá»‰ khi cáº§n hiá»ƒn thá»‹
                if self.display_enabled:
                    debug_processed = self.create_debug_image(
                        self.current_frame, binary, center_x, confidence, steering, angle)
                    
                    # Táº¡o combined debug image vá»›i bird's eye view
                    self.debug_frame = self.create_combined_debug_image(
                        self.current_frame, debug_processed, self.birdview_frame)
                    
                    # LÆ°u 3 áº£nh debug má»—i 1s (original+poly, birdview, processed)
                    now = time.time()
                    if now - self.last_debug_save_time > 1.0:
                        try:
                            # original+poly
                            original_poly = self.draw_birdview_polygon(self.current_frame)
                            cv2.imwrite(os.path.join(self.debug_save_dir, f"original_poly_{int(now)}.jpg"), original_poly)
                            # birdview
                            if self.birdview_frame is not None:
                                cv2.imwrite(os.path.join(self.debug_save_dir, f"birdview_{int(now)}.jpg"), self.birdview_frame)
                            # processed
                            cv2.imwrite(os.path.join(self.debug_save_dir, f"processed_{int(now)}.jpg"), debug_processed)
                            self.last_debug_save_time = now
                        except Exception as e:
                            print(f"âš ï¸ Lá»—i lÆ°u áº£nh debug: {e}")
                
                # Ghi video frame (chá»‰ ghi frame gá»‘c, resize vá» video_size)
                if self.recording_enabled and self.video_writer is not None:
                    try:
                        frame_to_write = cv2.resize(self.current_frame, self.video_size)
                        self.video_writer.write(frame_to_write)
                    except Exception as e:
                        print(f"âš ï¸ Lá»—i ghi video: {e}")
            except Exception as e:
                print(f"âŒ Lá»—i trong control loop: {e}")
                self.robot.stop()
                
            time.sleep(0.05)  # 20 FPS

    def display_loop(self):
        """VÃ²ng láº·p hiá»ƒn thá»‹ hÃ¬nh áº£nh"""
        if not self.display_enabled:
            # Cháº¿ Ä‘á»™ headless - chá»‰ chá» tÃ­n hiá»‡u dá»«ng
            print("ğŸ–¥ï¸ Cháº¡y trong cháº¿ Ä‘á»™ headless - nháº¥n Ctrl+C Ä‘á»ƒ dá»«ng")
            try:
                while self.running:
                    time.sleep(0.1)
            except KeyboardInterrupt:
                print("\nğŸ›‘ Nháº­n tÃ­n hiá»‡u Ctrl+C...")
                self.stop()
            return
        
        # Cháº¿ Ä‘á»™ cÃ³ GUI
        try:
            cv2.namedWindow('JetBot Line Following', cv2.WINDOW_AUTOSIZE)
            
            while self.running:
                if self.debug_frame is not None:
                    cv2.imshow('JetBot Line Following', self.debug_frame)
                    
                # Kiá»ƒm tra phÃ­m nháº¥n
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q') or key == 27:  # 'q' hoáº·c ESC
                    print("ğŸ›‘ NgÆ°á»i dÃ¹ng yÃªu cáº§u thoÃ¡t...")
                    self.stop()
                    break
                elif key == ord('r'):  # 'r' Ä‘á»ƒ toggle run mode
                    self.toggle_run_mode()
                    
                time.sleep(0.03)  # ~30 FPS cho display
            
            cv2.destroyAllWindows()
        except Exception as e:
            print(f"âš ï¸ Lá»—i hiá»ƒn thá»‹: {e} - Chuyá»ƒn sang cháº¿ Ä‘á»™ headless")
            # Fallback to headless mode
            try:
                while self.running:
                    time.sleep(0.1)
            except KeyboardInterrupt:
                print("\nğŸ›‘ Nháº­n tÃ­n hiá»‡u Ctrl+C...")
                self.stop()

    def start(self):
        """Báº¯t Ä‘áº§u line following"""
        if self.running:
            print("âš ï¸ Robot Ä‘Ã£ Ä‘ang cháº¡y!")
            return
            
        self.running = True
        
        # Báº¯t Ä‘áº§u camera callback
        self.camera.observe(self.camera_callback, names='value')
        
        # Táº¡o vÃ  báº¯t Ä‘áº§u cÃ¡c thread
        self.control_thread = threading.Thread(target=self.control_loop, daemon=True)
        self.display_thread = threading.Thread(target=self.display_loop, daemon=True)
        
        self.control_thread.start()
        self.display_thread.start()
        
        # ThÃªm console input thread cho cháº¿ Ä‘á»™ headless
        if not self.display_enabled:
            self.console_thread = threading.Thread(target=self.console_input_loop, daemon=True)
            self.console_thread.start()
        
        print("âœ… Line following Ä‘Ã£ báº¯t Ä‘áº§u!")
        if self.display_enabled:
            print("ğŸ’¡ Máº¹o: Nháº¥n 'q' trong cá»­a sá»• camera Ä‘á»ƒ dá»«ng, 'r' Ä‘á»ƒ chuyá»ƒn cháº¿ Ä‘á»™")
        else:
            print("ğŸ’¡ Máº¹o: Nháº¥n Ctrl+C Ä‘á»ƒ dá»«ng robot, hoáº·c gÃµ 'q' + Enter")
            print("ğŸ’¡ Trong cháº¿ Ä‘á»™ SSH: GÃµ 'r' + Enter Ä‘á»ƒ chuyá»ƒn cháº¿ Ä‘á»™")
        print("ğŸ“Š Theo dÃµi log Ä‘á»ƒ xem tráº¡ng thÃ¡i robot")
        
        # Chá» display thread káº¿t thÃºc (khi ngÆ°á»i dÃ¹ng nháº¥n 'q')
        try:
            self.display_thread.join()
        except KeyboardInterrupt:
            print("\nğŸ›‘ Nháº­n tÃ­n hiá»‡u Ctrl+C...")
            self.stop()

    def stop(self):
        """Dá»«ng line following"""
        if not self.running:
            return
            
        print("ğŸ›‘ Äang dá»«ng robot...")
        self.running = False
        
        # Ngáº¯t camera callback
        try:
            self.camera.unobserve(self.camera_callback, names='value')
        except:
            pass
        
        # Dá»«ng robot
        self.robot.stop()
        
        # Chá» threads káº¿t thÃºc
        time.sleep(0.2)
        
        print("âœ… Robot Ä‘Ã£ dá»«ng!")

    def cleanup(self):
        """Giáº£i phÃ³ng tÃ i nguyÃªn"""
        self.stop()
        try:
            self.camera.stop()
            print("ğŸ”Œ Camera Ä‘Ã£ Ä‘Æ°á»£c Ä‘Ã³ng")
        except:
            pass

def signal_handler(sig, frame):
    """Xá»­ lÃ½ tÃ­n hiá»‡u Ctrl+C"""
    print("\nğŸ›‘ Nháº­n tÃ­n hiá»‡u dá»«ng...")
    if 'follower' in globals():
        follower.cleanup()
    sys.exit(0)

def main():
    """HÃ m main"""
    print("=" * 60)
    print("ğŸ¤– JETBOT LINE FOLLOWING vá»›i COMPUTER VISION")
    print("=" * 60)
    print("ğŸ“‹ TÃ­nh nÄƒng:")
    print("   â€¢ Sá»­ dá»¥ng OpenCV Ä‘á»ƒ detect Ä‘Æ°á»ng mÃ u Ä‘en")
    print("   â€¢ Bird's Eye View transformation cho gÃ³c chÃ­nh xÃ¡c")
    print("   â€¢ Enhanced PID controller vá»›i angle prediction")
    print("   â€¢ Alignment mode: chá»‰ cÄƒn giá»¯a khÃ´ng cháº¡y theo Ä‘Æ°á»ng")
    print("   â€¢ Hiá»ƒn thá»‹ real-time debug window (3 views)")
    print("   â€¢ Load/Save thÃ´ng sá»‘ tá»« config.txt")
    print("   â€¢ Tá»± Ä‘á»™ng dá»«ng khi khÃ´ng tháº¥y Ä‘Æ°á»ng")
    print()
    print("ğŸ® Äiá»u khiá»ƒn:")
    print("   â€¢ Desktop: Nháº¥n 'q' trong cá»­a sá»• camera Ä‘á»ƒ thoÃ¡t")
    print("   â€¢ SSH: Nháº¥n Ctrl+C trong terminal Ä‘á»ƒ thoÃ¡t")
    print("   â€¢ Chá»‰nh sá»­a config.txt Ä‘á»ƒ Ä‘iá»u chá»‰nh thÃ´ng sá»‘")
    print("   â€¢ Tá»± Ä‘á»™ng phÃ¡t hiá»‡n mÃ´i trÆ°á»ng SSH/headless")
    print()
    print("âš™ï¸ Config:")
    print("   â€¢ run=true: cháº¡y theo Ä‘Æ°á»ng liÃªn tá»¥c")
    print("   â€¢ run=false: chá»‰ cÄƒn giá»¯a Ä‘Æ°á»ng rá»“i dá»«ng")
    print("   â€¢ alignment_threshold: ngÆ°á»¡ng Ä‘á»ƒ coi lÃ  Ä‘Ã£ cÄƒn giá»¯a")
    print()
    print("ğŸ“‹ YÃªu cáº§u:")
    print("   â€¢ ÄÆ°á»ng mÃ u Ä‘en trÃªn ná»n sÃ¡ng")
    print("   â€¢ Ãnh sÃ¡ng Ä‘á»u, khÃ´ng cÃ³ bÃ³ng Ä‘á»•")
    print("   â€¢ Robot cÃ³ Ä‘á»§ khÃ´ng gian an toÃ n")
    print("=" * 60)
    
    # ÄÄƒng kÃ½ signal handler
    signal.signal(signal.SIGINT, signal_handler)
    
    global follower
    follower = None
    
    try:
        # Táº¡o vÃ  khá»Ÿi Ä‘á»™ng line follower
        follower = LineFollower()
        
        input("\nğŸš€ Nháº¥n Enter Ä‘á»ƒ báº¯t Ä‘áº§u (hoáº·c Ctrl+C Ä‘á»ƒ thoÃ¡t)...")
        
        follower.start()
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ ChÆ°Æ¡ng trÃ¬nh bá»‹ giÃ¡n Ä‘oáº¡n")
    except Exception as e:
        print(f"âŒ Lá»—i: {e}")
    finally:
        if follower:
            follower.cleanup()

if __name__ == "__main__":
    main()